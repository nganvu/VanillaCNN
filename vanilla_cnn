#!/usr/bin/python3

import numpy as np

# Load MNISt dataset.
from keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Scale a set uniformly sampled from [0, 1] to [-bound, bound].
def scale_to_bound(arr, arr_bound):
	return arr * 2 * arr_bound - arr_bound

#################################
##### Convolutional Layer 1 #####
#################################
# (1 x 6) kernels of size (5 x 5).
K1 = np.random.rand(1, 6, 5, 5)
K1_bound = np.sqrt(6 / ((1 + 6) * (5 * 5)))
scale_to_bound(K1, K1_bound)

# 6 biases.
B1 = np.zeros(6)

# 6 convolution outputs of size (24 x 24).
C1 = np.zeros((6, 24, 24))

#################################
#####    Pooling Layer 1    #####
#################################
# 6 sampling outputs of size (12 x 12).
S1 = np.zeros((6, 12, 12))

#################################
##### Convolutional Layer 2 #####
#################################
# (6 x 12) kernels of size (5 x 5).
K2 = np.random.rand(6, 12, 5, 5)
K2_bound = np.sqrt(6 / ((6 + 12) * (5 * 5)))
scale_to_bound(K2, K2_bound)

# 12 biases.
B2 = np.random.rand(12)

# 12 convolution outputs of size (8 x 8).
C2 = np.zeros((12, 8, 8))

#################################
#####    Pooling Layer 2    #####
#################################
# 12 sampling outputs of size (4 x 4).
S2 = np.zeros((12, 4, 4))

#################################
##### Fully Connected Layer #####
#################################
# Vectorization of 12 matrices of size (4 x 4) to a vector of size 192.
F = np.zeros(192)

# 10 weights of size 192.
W = np.random.rand(10, 192)
W_bound = np.sqrt(6 / (192 + 10))
scale_to_bound(W, W_bound)

# 10 biases.
B = np.zeros(10)

# 10 output classes.
Y = np.zeros(10)

def convolution(in_img, kernel, out_img):
	# Assume the kernel is square and has an odd side length.
	u_length, v_length = kernel.shape
	assert(u_length == v_length and u_length % 2 == 1)

	# Make sure the shape of output matches the convolution of input and kernel.
	# Only keep the parts of input that are computed without zero-padded edges.
	xo_length, yo_length = out_img.shape
	xi_length, yi_length = in_img.shape
	assert(xi_length == xo_length + u_length - 1)
	assert(yi_length == yo_length + v_length - 1)

	u_margin = v_margin = int(u_length / 2)
	(u_lbound, u_ubound) = (v_lbound, v_ubound) = (-u_margin, u_margin)

	# Iterate through output image.
	for i in range(xo_length):
		for j in range(yo_length):
			# Iterate through kernel.
			for u in range(u_lbound, u_ubound):
				for v in range(v_lbound, v_ubound):
					# Ignore parts that require zero-padded edges.
					if ((i - u < 0 or i - u >= xi_length) or
						(j - v < 0 or j - v >= yi_length)):
						continue
					else:
						out_img[i][j] = in_img[i - u][j - v] * \
							kernel[u + u_margin][v + v_margin]

# Check for syntatical correctness (not logical correctness yet).
I = x_train[0]
convolution(I, K1[0][0], C1[0])

def pooling(in_img, out_img):
	# Make sure the side length of output is half the side length of the input.
	# Assume the side length of the input is even.
	xo_length, yo_length = out_img.shape
	xi_length, yi_length = in_img.shape
	assert(xi_length % 2 == 0 and yi_length % 2 == 0)
	assert(xi_length == 2 * xo_length)
	assert(yi_length == 2 * yo_length)

	# Iterate through the output image.
	for i in range(xo_length):
		for j in range(yo_length):
			out_img[i][j] = 0.25 * (in_img[2*i    ][2*j    ] + 
															in_img[2*i + 1][2*j    ] + 
															in_img[2*i    ][2*j + 1] +
															in_img[2*i + 1][2*j + 1])

# Check for syntatical correctness (not logical correctness yet).
pooling(C1[0], S1[0])



